{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import patches\n",
        "\n",
        "import cv2\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch import nn\n",
        "import albumentations as A\n",
        "from albumentations.pytorch.transforms import ToTensorV2\n",
        "from torch.utils import data as torch_data\n",
        "from torchvision import transforms as T\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image \n",
        "from xml.etree import ElementTree as ET\n",
        "import glob \n",
        "from torch.utils.data import DataLoader\n",
        "from copy import deepcopy\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2023-04-17T07:13:38.398893Z",
          "iopub.execute_input": "2023-04-17T07:13:38.399177Z",
          "iopub.status.idle": "2023-04-17T07:13:43.297127Z",
          "shell.execute_reply.started": "2023-04-17T07:13:38.399148Z",
          "shell.execute_reply": "2023-04-17T07:13:43.296058Z"
        },
        "trusted": true,
        "id": "xh8shCpOQ-Pw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-17T07:13:43.299076Z",
          "iopub.execute_input": "2023-04-17T07:13:43.299620Z",
          "iopub.status.idle": "2023-04-17T07:13:43.367531Z",
          "shell.execute_reply.started": "2023-04-17T07:13:43.299588Z",
          "shell.execute_reply": "2023-04-17T07:13:43.364836Z"
        },
        "trusted": true,
        "id": "qiQJuX4zQ-Py",
        "outputId": "1c5aa560-0906-48ee-8106-fa1346762251",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# kaggle api를 사용할 수 있는 패키지 설치\n",
        "!pip install kaggle\n",
        "\n",
        "# kaggle.json upload\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "\n",
        "# permmision warning 방지\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# download\n",
        "!kaggle datasets download -d jessicali9530/stanford-dogs-dataset\n",
        "# unzip(압축풀기)\n",
        "!unzip -q stanford-dogs-dataset.zip -d stanford-dogs-dataset"
      ],
      "metadata": {
        "id": "6TZYX_QGg7qM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "outputId": "c24d85d3-21f7-451d-a13e-e94a7ed28374"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.9/dist-packages (1.5.13)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.9/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.9/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.9/dist-packages (from kaggle) (2022.12.7)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.9/dist-packages (from kaggle) (1.26.15)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.9/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from kaggle) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from kaggle) (4.65.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.9/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->kaggle) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->kaggle) (2.0.12)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4fe996c7-a44e-4c41-b59c-849ae0c0549a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4fe996c7-a44e-4c41-b59c-849ae0c0549a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle (1).json\n",
            "Downloading stanford-dogs-dataset.zip to /content\n",
            " 98% 737M/750M [00:04<00:00, 196MB/s]\n",
            "100% 750M/750M [00:04<00:00, 182MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 시각화"
      ],
      "metadata": {
        "id": "Y3-tUXXDQ-Pz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "root_dir = '/content/stanford-dogs-dataset'\n",
        "img_dir = '/images/Images/'\n",
        "annot_dir = '/annotations/Annotation/'"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-17T07:13:53.718259Z",
          "iopub.execute_input": "2023-04-17T07:13:53.719031Z",
          "iopub.status.idle": "2023-04-17T07:13:53.723829Z",
          "shell.execute_reply.started": "2023-04-17T07:13:53.718991Z",
          "shell.execute_reply": "2023-04-17T07:13:53.722659Z"
        },
        "trusted": true,
        "id": "vj5ZLRmXQ-P9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "labels_map = {}\n",
        "for i, item in enumerate(os.listdir(root_dir + img_dir)):\n",
        "    sub_folder = os.path.join(root_dir + img_dir, item)\n",
        "    labels_map[sub_folder.split('-', maxsplit=3)[-1]] = i"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-17T07:13:55.762586Z",
          "iopub.execute_input": "2023-04-17T07:13:55.763266Z",
          "iopub.status.idle": "2023-04-17T07:13:55.787211Z",
          "shell.execute_reply.started": "2023-04-17T07:13:55.763221Z",
          "shell.execute_reply": "2023-04-17T07:13:55.786259Z"
        },
        "trusted": true,
        "id": "legp3CBjQ-P9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def img_crop(annot_path, img):\n",
        "    tree = ET.parse(annot_path)\n",
        "    obj = tree.find('./object')\n",
        "    bndbox = obj.find('bndbox')\n",
        "\n",
        "    # 강아지 종류\n",
        "    species = obj.find('name').text\n",
        "\n",
        "    # 이미지에서의 강아지 위치\n",
        "    xmin = int(bndbox.find('xmin').text)\n",
        "    ymin = int(bndbox.find('ymin').text)\n",
        "    xmax = int(bndbox.find('xmax').text)\n",
        "    ymax = int(bndbox.find('ymax').text)\n",
        "\n",
        "    cropped_img = img[ymin:ymax, xmin:xmax]\n",
        "    \n",
        "    label = labels_map.get(species)\n",
        "\n",
        "    return label, cropped_img"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-17T07:13:56.253206Z",
          "iopub.execute_input": "2023-04-17T07:13:56.253596Z",
          "iopub.status.idle": "2023-04-17T07:13:56.260974Z",
          "shell.execute_reply.started": "2023-04-17T07:13:56.253560Z",
          "shell.execute_reply": "2023-04-17T07:13:56.259628Z"
        },
        "trusted": true,
        "id": "alLuHp0WQ-P-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DogsDataset(Dataset):\n",
        "    def __init__(self, annot_dir, img_dir, transform=None):\n",
        "        annot_dir = glob.glob(root_dir + annot_dir + '*/*')\n",
        "        img_dir = glob.glob(root_dir + img_dir + '*/*.jpg')\n",
        "        self.annot_dir = sorted(annot_dir)\n",
        "        self.img_dir = sorted(img_dir)\n",
        "        self.transform = transform\n",
        "   \n",
        "    def __len__(self):\n",
        "        return len(self.img_dir)\n",
        "        \n",
        "    def __getitem__(self, idx):\n",
        "        annot_path = self.annot_dir[idx]\n",
        "        img_path = self.img_dir[idx]\n",
        "        \n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        \n",
        "        label, img = img_crop(annot_path, img)\n",
        "        \n",
        "        if self.transform is not None:\n",
        "            img = self.transform(image=img)\n",
        "            img['label'] = label\n",
        "            return img\n",
        "            \n",
        "        sample = {'image': img, 'label': label}\n",
        "        return sample"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-17T07:14:00.233616Z",
          "iopub.execute_input": "2023-04-17T07:14:00.234304Z",
          "iopub.status.idle": "2023-04-17T07:14:00.242703Z",
          "shell.execute_reply.started": "2023-04-17T07:14:00.234265Z",
          "shell.execute_reply": "2023-04-17T07:14:00.241478Z"
        },
        "trusted": true,
        "id": "H9x1kHWoQ-P-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "augmentor = A.OneOf([\n",
        "    A.VerticalFlip(p=1),\n",
        "    A.HorizontalFlip(p=1),\n",
        "    A.CLAHE(p=1)])"
      ],
      "metadata": {
        "id": "OCtQyGhHQ-P-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_transform = A.Compose([A.Resize(224, 224),augmentor, A.Normalize(), ToTensorV2()])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-17T07:14:03.456395Z",
          "iopub.execute_input": "2023-04-17T07:14:03.456899Z",
          "iopub.status.idle": "2023-04-17T07:14:03.467123Z",
          "shell.execute_reply.started": "2023-04-17T07:14:03.456852Z",
          "shell.execute_reply": "2023-04-17T07:14:03.466133Z"
        },
        "trusted": true,
        "id": "t7IM7fXSQ-P_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "sN9YHI3HQ-P_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_dataset = DogsDataset(annot_dir ='/annotations/Annotation/',\n",
        "                            img_dir ='/images/Images/', transform=data_transform)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-17T07:14:05.904575Z",
          "iopub.execute_input": "2023-04-17T07:14:05.905176Z",
          "iopub.status.idle": "2023-04-17T07:14:15.558330Z",
          "shell.execute_reply.started": "2023-04-17T07:14:05.905139Z",
          "shell.execute_reply": "2023-04-17T07:14:15.557169Z"
        },
        "trusted": true,
        "id": "dZVKlyNbQ-P_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(image_dataset)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-17T07:14:27.809375Z",
          "iopub.execute_input": "2023-04-17T07:14:27.810385Z",
          "iopub.status.idle": "2023-04-17T07:14:27.817282Z",
          "shell.execute_reply.started": "2023-04-17T07:14:27.810345Z",
          "shell.execute_reply": "2023-04-17T07:14:27.816030Z"
        },
        "trusted": true,
        "id": "aYQY7cBuQ-P_",
        "outputId": "8d8a7c7c-a82e-4ed6-cabd-dabe38b625c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20580"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_dataset[0]['label']"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-17T07:14:39.347324Z",
          "iopub.execute_input": "2023-04-17T07:14:39.347923Z",
          "iopub.status.idle": "2023-04-17T07:14:39.415348Z",
          "shell.execute_reply.started": "2023-04-17T07:14:39.347885Z",
          "shell.execute_reply": "2023-04-17T07:14:39.414298Z"
        },
        "trusted": true,
        "id": "wj6zaCHgQ-P_",
        "outputId": "52ac253e-e382-406b-dfae-391df001c92b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_dataset[0][\"image\"].shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-17T07:14:44.857399Z",
          "iopub.execute_input": "2023-04-17T07:14:44.857885Z",
          "iopub.status.idle": "2023-04-17T07:14:44.881633Z",
          "shell.execute_reply.started": "2023-04-17T07:14:44.857837Z",
          "shell.execute_reply": "2023-04-17T07:14:44.880618Z"
        },
        "trusted": true,
        "id": "brDjdMIvQ-QA",
        "outputId": "95c20ccb-b665-4905-971d-bab85fb4d7a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 224, 224])"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_dataset[0][\"label\"]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-17T07:14:49.197158Z",
          "iopub.execute_input": "2023-04-17T07:14:49.197748Z",
          "iopub.status.idle": "2023-04-17T07:14:49.211030Z",
          "shell.execute_reply.started": "2023-04-17T07:14:49.197710Z",
          "shell.execute_reply": "2023-04-17T07:14:49.209872Z"
        },
        "trusted": true,
        "id": "-Dsb-eZxQ-QA",
        "outputId": "9c299477-90db-41a0-f1ed-4ff11fa8d469",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Subset\n",
        "\n",
        "total_label = [data['label'] for data in image_dataset]\n",
        "\n",
        "trainset_idx, testset_idx = train_test_split(range(len(image_dataset)),\n",
        "                test_size=0.2, random_state=42, shuffle=True, stratify=total_label)\n",
        "\n",
        "# 전체 데이터 셋에서 train과 test로 나누기\n",
        "train_set = Subset(image_dataset, trainset_idx)\n",
        "test_set = Subset(image_dataset, testset_idx)\n",
        "\n",
        "# train label\n",
        "train_label = [data['label'] for data in train_set]\n",
        "\n",
        "# train idx와 valid idx\n",
        "trainset_idx, validset_idx = train_test_split(range(len(trainset_idx)),\n",
        "                test_size=0.2, random_state=42, shuffle=True, stratify=train_label)\n",
        "\n",
        "# train set에서 train과 valid로 나누기\n",
        "from torch.utils.data import Subset\n",
        "trainset = Subset(train_set, trainset_idx)\n",
        "validset = Subset(train_set, validset_idx)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-17T07:15:41.376243Z",
          "iopub.execute_input": "2023-04-17T07:15:41.377038Z",
          "iopub.status.idle": "2023-04-17T07:21:42.844091Z",
          "shell.execute_reply.started": "2023-04-17T07:15:41.376999Z",
          "shell.execute_reply": "2023-04-17T07:21:42.843048Z"
        },
        "trusted": true,
        "id": "2GQUG5e7Q-QA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(trainset), len(trainset))\n",
        "print(type(validset), len(validset))\n",
        "print(type(test_set), len(test_set))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-17T07:21:54.229538Z",
          "iopub.execute_input": "2023-04-17T07:21:54.230032Z",
          "iopub.status.idle": "2023-04-17T07:21:54.236199Z",
          "shell.execute_reply.started": "2023-04-17T07:21:54.229994Z",
          "shell.execute_reply": "2023-04-17T07:21:54.235151Z"
        },
        "trusted": true,
        "id": "r0oc9KqWQ-QA",
        "outputId": "3e6a568f-5833-4363-fcce-9c92bbc33def",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.utils.data.dataset.Subset'> 13171\n",
            "<class 'torch.utils.data.dataset.Subset'> 3293\n",
            "<class 'torch.utils.data.dataset.Subset'> 4116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(trainset[0]['image'].shape)\n",
        "print(validset[0]['image'].shape)\n",
        "print(test_set[0]['image'].shape)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-17T07:21:56.556259Z",
          "iopub.execute_input": "2023-04-17T07:21:56.557196Z",
          "iopub.status.idle": "2023-04-17T07:21:56.580831Z",
          "shell.execute_reply.started": "2023-04-17T07:21:56.557158Z",
          "shell.execute_reply": "2023-04-17T07:21:56.579883Z"
        },
        "trusted": true,
        "id": "qZbL2xWKQ-QA",
        "outputId": "63f26383-c5dd-4083-c59f-9cffbdb0ab40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 224, 224])\n",
            "torch.Size([3, 224, 224])\n",
            "torch.Size([3, 224, 224])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "UX55gK-eQ-QB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16 # 100 -> 16\n",
        "# dataloader = DataLoader(데이터셋, 배치사이즈, 셔플여부.....)\n",
        "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True) # 훈련용 13171개의 데이터를 100개씩 준비\n",
        "validloader = DataLoader(validset, batch_size=batch_size, shuffle=False) # 검증용 10000개의 데이터를 100개씩 준비\n",
        "testloader = DataLoader(test_set, batch_size=batch_size, shuffle=False) # 테스트용 10000개의 데이터를 100개씩 준비"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-17T07:21:58.892697Z",
          "iopub.execute_input": "2023-04-17T07:21:58.893289Z",
          "iopub.status.idle": "2023-04-17T07:21:58.899068Z",
          "shell.execute_reply.started": "2023-04-17T07:21:58.893254Z",
          "shell.execute_reply": "2023-04-17T07:21:58.897984Z"
        },
        "trusted": true,
        "id": "CxYH0Oo0Q-QB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(trainloader), len(trainloader))\n",
        "print(type(validloader), len(validloader))\n",
        "print(type(testloader), len(testloader))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-17T07:22:00.970317Z",
          "iopub.execute_input": "2023-04-17T07:22:00.970918Z",
          "iopub.status.idle": "2023-04-17T07:22:00.977117Z",
          "shell.execute_reply.started": "2023-04-17T07:22:00.970879Z",
          "shell.execute_reply": "2023-04-17T07:22:00.976049Z"
        },
        "trusted": true,
        "id": "X8rgX6W0Q-QB",
        "outputId": "5bc0a3d4-8af8-4196-a341-d016e3db7a5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.utils.data.dataloader.DataLoader'> 824\n",
            "<class 'torch.utils.data.dataloader.DataLoader'> 206\n",
            "<class 'torch.utils.data.dataloader.DataLoader'> 258\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "13171/16, 3293/16, 4116/16"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-17T07:22:03.421319Z",
          "iopub.execute_input": "2023-04-17T07:22:03.421951Z",
          "iopub.status.idle": "2023-04-17T07:22:03.428871Z",
          "shell.execute_reply.started": "2023-04-17T07:22:03.421904Z",
          "shell.execute_reply": "2023-04-17T07:22:03.427565Z"
        },
        "trusted": true,
        "id": "f8qwhS_PQ-QB",
        "outputId": "2944f930-3a84-41fc-8a2d-f48af780cc41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(823.1875, 205.8125, 257.25)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_iter = iter(trainloader)\n",
        "batch = next(train_iter)\n",
        "batch['image'].size(), batch['label'].shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-17T07:22:05.435898Z",
          "iopub.execute_input": "2023-04-17T07:22:05.436535Z",
          "iopub.status.idle": "2023-04-17T07:22:05.576773Z",
          "shell.execute_reply.started": "2023-04-17T07:22:05.436501Z",
          "shell.execute_reply": "2023-04-17T07:22:05.575829Z"
        },
        "trusted": true,
        "id": "7bIKBT-KQ-QB",
        "outputId": "013ff411-d099-445d-8f83-c3a780b480f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([16, 3, 224, 224]), torch.Size([16]))"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn # 파이토치에서 제공하는 다양한 계층 (Linear Layer, ....)\n",
        "import torch.optim as optim # 옵티마이저 (경사하강법...)\n",
        "import torch.nn.functional as F # 파이토치에서 제공하는 함수(활성화 함수...)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-17T07:22:07.859531Z",
          "iopub.execute_input": "2023-04-17T07:22:07.860015Z",
          "iopub.status.idle": "2023-04-17T07:22:07.865676Z",
          "shell.execute_reply.started": "2023-04-17T07:22:07.859977Z",
          "shell.execute_reply": "2023-04-17T07:22:07.864333Z"
        },
        "trusted": true,
        "id": "QT0m8ZsaQ-QC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.models as models\n",
        "\n",
        "model = models.resnet50(weights=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-17T07:22:10.350320Z",
          "iopub.execute_input": "2023-04-17T07:22:10.350683Z",
          "iopub.status.idle": "2023-04-17T07:22:12.490841Z",
          "shell.execute_reply.started": "2023-04-17T07:22:10.350650Z",
          "shell.execute_reply": "2023-04-17T07:22:12.489742Z"
        },
        "trusted": true,
        "id": "5kGUYSV_Q-QC",
        "outputId": "d86a0931-a2c8-47ec-fca5-7c683a9415f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 221MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for parameter in model.parameters():\n",
        "  print(parameter.requires_grad)\n",
        "# parameter들의 requires_grad 속성이 true라는 것은 오차역전파를 통해 gradient를 전달할 수 있는 상태(즉, 학습이 가능한 상태)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-17T07:22:18.735463Z",
          "iopub.execute_input": "2023-04-17T07:22:18.736176Z",
          "iopub.status.idle": "2023-04-17T07:22:18.743750Z",
          "shell.execute_reply.started": "2023-04-17T07:22:18.736136Z",
          "shell.execute_reply": "2023-04-17T07:22:18.742615Z"
        },
        "trusted": true,
        "id": "poYxkfq2Q-QC",
        "outputId": "6dbcef35-dd5a-4666-8fc5-db753c983d8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for parameter in model.parameters():\n",
        "    parameter.requires_grad = False # 학습이 안되게 고정\n",
        "\n",
        "for parameter in model.fc.parameters():\n",
        "    parameter.requires_grad = True # 학습이 가능한 상태 "
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-17T07:23:12.789407Z",
          "iopub.execute_input": "2023-04-17T07:23:12.790104Z",
          "iopub.status.idle": "2023-04-17T07:23:12.798276Z",
          "shell.execute_reply.started": "2023-04-17T07:23:12.790065Z",
          "shell.execute_reply": "2023-04-17T07:23:12.797112Z"
        },
        "trusted": true,
        "id": "r0vP0tDHQ-QC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.classifier[3] = nn.Linear(in_features=4096, out_features=512, bias=True)\n",
        "# model.classifier[6] = nn.Linear(in_features=512, out_features=2, bias=True)\n",
        "model.fc = nn.Linear(in_features=2048, out_features=120, bias=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-17T07:23:48.162656Z",
          "iopub.execute_input": "2023-04-17T07:23:48.163641Z",
          "iopub.status.idle": "2023-04-17T07:23:48.172172Z",
          "shell.execute_reply.started": "2023-04-17T07:23:48.163602Z",
          "shell.execute_reply": "2023-04-17T07:23:48.170767Z"
        },
        "trusted": true,
        "id": "l-ZKLTVeQ-QC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-17T07:23:50.489237Z",
          "iopub.execute_input": "2023-04-17T07:23:50.490253Z",
          "iopub.status.idle": "2023-04-17T07:23:53.348791Z",
          "shell.execute_reply.started": "2023-04-17T07:23:50.490214Z",
          "shell.execute_reply": "2023-04-17T07:23:53.347743Z"
        },
        "trusted": true,
        "id": "nHpseuQcQ-QC",
        "outputId": "1e04347f-86f2-4c3c-ddcd-74fb7efa07e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=2048, out_features=120, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out = model(batch['image'].to(device))\n",
        "out.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-17T07:24:28.090788Z",
          "iopub.execute_input": "2023-04-17T07:24:28.091280Z",
          "iopub.status.idle": "2023-04-17T07:24:31.838832Z",
          "shell.execute_reply.started": "2023-04-17T07:24:28.091237Z",
          "shell.execute_reply": "2023-04-17T07:24:31.837751Z"
        },
        "trusted": true,
        "id": "x373G19xQ-QC",
        "outputId": "5211200a-bb49-4eb8-df66-523a195a3895",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 120])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, parameter in model.named_parameters():\n",
        "    print(name, parameter.size())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-17T07:25:01.173329Z",
          "iopub.execute_input": "2023-04-17T07:25:01.173692Z",
          "iopub.status.idle": "2023-04-17T07:25:01.182460Z",
          "shell.execute_reply.started": "2023-04-17T07:25:01.173659Z",
          "shell.execute_reply": "2023-04-17T07:25:01.181236Z"
        },
        "trusted": true,
        "id": "6gKOeI-xQ-QD",
        "outputId": "c847df72-627e-4772-99e7-a1cde0c7b0d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conv1.weight torch.Size([64, 3, 7, 7])\n",
            "bn1.weight torch.Size([64])\n",
            "bn1.bias torch.Size([64])\n",
            "layer1.0.conv1.weight torch.Size([64, 64, 1, 1])\n",
            "layer1.0.bn1.weight torch.Size([64])\n",
            "layer1.0.bn1.bias torch.Size([64])\n",
            "layer1.0.conv2.weight torch.Size([64, 64, 3, 3])\n",
            "layer1.0.bn2.weight torch.Size([64])\n",
            "layer1.0.bn2.bias torch.Size([64])\n",
            "layer1.0.conv3.weight torch.Size([256, 64, 1, 1])\n",
            "layer1.0.bn3.weight torch.Size([256])\n",
            "layer1.0.bn3.bias torch.Size([256])\n",
            "layer1.0.downsample.0.weight torch.Size([256, 64, 1, 1])\n",
            "layer1.0.downsample.1.weight torch.Size([256])\n",
            "layer1.0.downsample.1.bias torch.Size([256])\n",
            "layer1.1.conv1.weight torch.Size([64, 256, 1, 1])\n",
            "layer1.1.bn1.weight torch.Size([64])\n",
            "layer1.1.bn1.bias torch.Size([64])\n",
            "layer1.1.conv2.weight torch.Size([64, 64, 3, 3])\n",
            "layer1.1.bn2.weight torch.Size([64])\n",
            "layer1.1.bn2.bias torch.Size([64])\n",
            "layer1.1.conv3.weight torch.Size([256, 64, 1, 1])\n",
            "layer1.1.bn3.weight torch.Size([256])\n",
            "layer1.1.bn3.bias torch.Size([256])\n",
            "layer1.2.conv1.weight torch.Size([64, 256, 1, 1])\n",
            "layer1.2.bn1.weight torch.Size([64])\n",
            "layer1.2.bn1.bias torch.Size([64])\n",
            "layer1.2.conv2.weight torch.Size([64, 64, 3, 3])\n",
            "layer1.2.bn2.weight torch.Size([64])\n",
            "layer1.2.bn2.bias torch.Size([64])\n",
            "layer1.2.conv3.weight torch.Size([256, 64, 1, 1])\n",
            "layer1.2.bn3.weight torch.Size([256])\n",
            "layer1.2.bn3.bias torch.Size([256])\n",
            "layer2.0.conv1.weight torch.Size([128, 256, 1, 1])\n",
            "layer2.0.bn1.weight torch.Size([128])\n",
            "layer2.0.bn1.bias torch.Size([128])\n",
            "layer2.0.conv2.weight torch.Size([128, 128, 3, 3])\n",
            "layer2.0.bn2.weight torch.Size([128])\n",
            "layer2.0.bn2.bias torch.Size([128])\n",
            "layer2.0.conv3.weight torch.Size([512, 128, 1, 1])\n",
            "layer2.0.bn3.weight torch.Size([512])\n",
            "layer2.0.bn3.bias torch.Size([512])\n",
            "layer2.0.downsample.0.weight torch.Size([512, 256, 1, 1])\n",
            "layer2.0.downsample.1.weight torch.Size([512])\n",
            "layer2.0.downsample.1.bias torch.Size([512])\n",
            "layer2.1.conv1.weight torch.Size([128, 512, 1, 1])\n",
            "layer2.1.bn1.weight torch.Size([128])\n",
            "layer2.1.bn1.bias torch.Size([128])\n",
            "layer2.1.conv2.weight torch.Size([128, 128, 3, 3])\n",
            "layer2.1.bn2.weight torch.Size([128])\n",
            "layer2.1.bn2.bias torch.Size([128])\n",
            "layer2.1.conv3.weight torch.Size([512, 128, 1, 1])\n",
            "layer2.1.bn3.weight torch.Size([512])\n",
            "layer2.1.bn3.bias torch.Size([512])\n",
            "layer2.2.conv1.weight torch.Size([128, 512, 1, 1])\n",
            "layer2.2.bn1.weight torch.Size([128])\n",
            "layer2.2.bn1.bias torch.Size([128])\n",
            "layer2.2.conv2.weight torch.Size([128, 128, 3, 3])\n",
            "layer2.2.bn2.weight torch.Size([128])\n",
            "layer2.2.bn2.bias torch.Size([128])\n",
            "layer2.2.conv3.weight torch.Size([512, 128, 1, 1])\n",
            "layer2.2.bn3.weight torch.Size([512])\n",
            "layer2.2.bn3.bias torch.Size([512])\n",
            "layer2.3.conv1.weight torch.Size([128, 512, 1, 1])\n",
            "layer2.3.bn1.weight torch.Size([128])\n",
            "layer2.3.bn1.bias torch.Size([128])\n",
            "layer2.3.conv2.weight torch.Size([128, 128, 3, 3])\n",
            "layer2.3.bn2.weight torch.Size([128])\n",
            "layer2.3.bn2.bias torch.Size([128])\n",
            "layer2.3.conv3.weight torch.Size([512, 128, 1, 1])\n",
            "layer2.3.bn3.weight torch.Size([512])\n",
            "layer2.3.bn3.bias torch.Size([512])\n",
            "layer3.0.conv1.weight torch.Size([256, 512, 1, 1])\n",
            "layer3.0.bn1.weight torch.Size([256])\n",
            "layer3.0.bn1.bias torch.Size([256])\n",
            "layer3.0.conv2.weight torch.Size([256, 256, 3, 3])\n",
            "layer3.0.bn2.weight torch.Size([256])\n",
            "layer3.0.bn2.bias torch.Size([256])\n",
            "layer3.0.conv3.weight torch.Size([1024, 256, 1, 1])\n",
            "layer3.0.bn3.weight torch.Size([1024])\n",
            "layer3.0.bn3.bias torch.Size([1024])\n",
            "layer3.0.downsample.0.weight torch.Size([1024, 512, 1, 1])\n",
            "layer3.0.downsample.1.weight torch.Size([1024])\n",
            "layer3.0.downsample.1.bias torch.Size([1024])\n",
            "layer3.1.conv1.weight torch.Size([256, 1024, 1, 1])\n",
            "layer3.1.bn1.weight torch.Size([256])\n",
            "layer3.1.bn1.bias torch.Size([256])\n",
            "layer3.1.conv2.weight torch.Size([256, 256, 3, 3])\n",
            "layer3.1.bn2.weight torch.Size([256])\n",
            "layer3.1.bn2.bias torch.Size([256])\n",
            "layer3.1.conv3.weight torch.Size([1024, 256, 1, 1])\n",
            "layer3.1.bn3.weight torch.Size([1024])\n",
            "layer3.1.bn3.bias torch.Size([1024])\n",
            "layer3.2.conv1.weight torch.Size([256, 1024, 1, 1])\n",
            "layer3.2.bn1.weight torch.Size([256])\n",
            "layer3.2.bn1.bias torch.Size([256])\n",
            "layer3.2.conv2.weight torch.Size([256, 256, 3, 3])\n",
            "layer3.2.bn2.weight torch.Size([256])\n",
            "layer3.2.bn2.bias torch.Size([256])\n",
            "layer3.2.conv3.weight torch.Size([1024, 256, 1, 1])\n",
            "layer3.2.bn3.weight torch.Size([1024])\n",
            "layer3.2.bn3.bias torch.Size([1024])\n",
            "layer3.3.conv1.weight torch.Size([256, 1024, 1, 1])\n",
            "layer3.3.bn1.weight torch.Size([256])\n",
            "layer3.3.bn1.bias torch.Size([256])\n",
            "layer3.3.conv2.weight torch.Size([256, 256, 3, 3])\n",
            "layer3.3.bn2.weight torch.Size([256])\n",
            "layer3.3.bn2.bias torch.Size([256])\n",
            "layer3.3.conv3.weight torch.Size([1024, 256, 1, 1])\n",
            "layer3.3.bn3.weight torch.Size([1024])\n",
            "layer3.3.bn3.bias torch.Size([1024])\n",
            "layer3.4.conv1.weight torch.Size([256, 1024, 1, 1])\n",
            "layer3.4.bn1.weight torch.Size([256])\n",
            "layer3.4.bn1.bias torch.Size([256])\n",
            "layer3.4.conv2.weight torch.Size([256, 256, 3, 3])\n",
            "layer3.4.bn2.weight torch.Size([256])\n",
            "layer3.4.bn2.bias torch.Size([256])\n",
            "layer3.4.conv3.weight torch.Size([1024, 256, 1, 1])\n",
            "layer3.4.bn3.weight torch.Size([1024])\n",
            "layer3.4.bn3.bias torch.Size([1024])\n",
            "layer3.5.conv1.weight torch.Size([256, 1024, 1, 1])\n",
            "layer3.5.bn1.weight torch.Size([256])\n",
            "layer3.5.bn1.bias torch.Size([256])\n",
            "layer3.5.conv2.weight torch.Size([256, 256, 3, 3])\n",
            "layer3.5.bn2.weight torch.Size([256])\n",
            "layer3.5.bn2.bias torch.Size([256])\n",
            "layer3.5.conv3.weight torch.Size([1024, 256, 1, 1])\n",
            "layer3.5.bn3.weight torch.Size([1024])\n",
            "layer3.5.bn3.bias torch.Size([1024])\n",
            "layer4.0.conv1.weight torch.Size([512, 1024, 1, 1])\n",
            "layer4.0.bn1.weight torch.Size([512])\n",
            "layer4.0.bn1.bias torch.Size([512])\n",
            "layer4.0.conv2.weight torch.Size([512, 512, 3, 3])\n",
            "layer4.0.bn2.weight torch.Size([512])\n",
            "layer4.0.bn2.bias torch.Size([512])\n",
            "layer4.0.conv3.weight torch.Size([2048, 512, 1, 1])\n",
            "layer4.0.bn3.weight torch.Size([2048])\n",
            "layer4.0.bn3.bias torch.Size([2048])\n",
            "layer4.0.downsample.0.weight torch.Size([2048, 1024, 1, 1])\n",
            "layer4.0.downsample.1.weight torch.Size([2048])\n",
            "layer4.0.downsample.1.bias torch.Size([2048])\n",
            "layer4.1.conv1.weight torch.Size([512, 2048, 1, 1])\n",
            "layer4.1.bn1.weight torch.Size([512])\n",
            "layer4.1.bn1.bias torch.Size([512])\n",
            "layer4.1.conv2.weight torch.Size([512, 512, 3, 3])\n",
            "layer4.1.bn2.weight torch.Size([512])\n",
            "layer4.1.bn2.bias torch.Size([512])\n",
            "layer4.1.conv3.weight torch.Size([2048, 512, 1, 1])\n",
            "layer4.1.bn3.weight torch.Size([2048])\n",
            "layer4.1.bn3.bias torch.Size([2048])\n",
            "layer4.2.conv1.weight torch.Size([512, 2048, 1, 1])\n",
            "layer4.2.bn1.weight torch.Size([512])\n",
            "layer4.2.bn1.bias torch.Size([512])\n",
            "layer4.2.conv2.weight torch.Size([512, 512, 3, 3])\n",
            "layer4.2.bn2.weight torch.Size([512])\n",
            "layer4.2.bn2.bias torch.Size([512])\n",
            "layer4.2.conv3.weight torch.Size([2048, 512, 1, 1])\n",
            "layer4.2.bn3.weight torch.Size([2048])\n",
            "layer4.2.bn3.bias torch.Size([2048])\n",
            "fc.weight torch.Size([120, 2048])\n",
            "fc.bias torch.Size([120])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "# 손실함수\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# 옵티마이저(최적화함수, 예:경사하강법)\n",
        "# optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# 규제의 강도 설정 weight_decay\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "# optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.001)\n",
        "\n",
        "# Learning Rate Schedule\n",
        "# https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.ReduceLROnPlateau.html\n",
        "\n",
        "# 모니터링하고 있는 값(예:valid_loss)의 최소값(min) 또는 최대값(max) patience 기간동안 줄어들지 않을 때(OnPlateau) lr에 factor(0.1)를 곱해주는 전략\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=4, verbose=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-17T07:25:05.291504Z",
          "iopub.execute_input": "2023-04-17T07:25:05.292215Z",
          "iopub.status.idle": "2023-04-17T07:25:05.299245Z",
          "shell.execute_reply.started": "2023-04-17T07:25:05.292174Z",
          "shell.execute_reply": "2023-04-17T07:25:05.298104Z"
        },
        "trusted": true,
        "id": "SS_AArOLQ-QD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(model, validloader, loss_fn):\n",
        "    total = 0   \n",
        "    correct = 0\n",
        "    valid_loss = 0\n",
        "    valid_accuracy = 0\n",
        "\n",
        "  # 전방향 예측을 구할 때는 gradient가 필요가 없음음\n",
        "    with torch.no_grad():\n",
        "        for batch in validloader:# 이터레이터로부터 next()가 호출되며 미니배치를 반환(images, labels)      \n",
        "          # images, labels : (torch.Size([16, 3, 224, 224]), torch.Size([16]))\n",
        "          # 0. Data를 GPU로 보내기\n",
        "            images = batch['image']\n",
        "            labels = batch['label']\n",
        "            \n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            \n",
        "            # 1. 입력 데이터 준비\n",
        "            # not Flatten !!\n",
        "            # images.resize_(images.size()[0], 784)\n",
        "  \n",
        "            # 2. 전방향(Forward) 예측\n",
        "            logit = model(images) # 예측 점수\n",
        "            _, preds = torch.max(logit, 1) # 배치에 대한 최종 예측\n",
        "            # preds = logit.max(dim=1)[1] \n",
        "            correct += int((preds == labels).sum()) # 배치 중 맞은 것의 개수가 correct에 누적\n",
        "            total += labels.shape[0] # 배치 사이즈만큼씩 total에 누적\n",
        "\n",
        "            loss = loss_fn(logit, labels)\n",
        "            valid_loss += loss.item() # tensor에서 값을 꺼내와서, 배치의 loss 평균값을 valid_loss에 누적\n",
        "\n",
        "        valid_accuracy = correct / total\n",
        "  \n",
        "    return valid_loss, valid_accuracy"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-17T07:25:11.985518Z",
          "iopub.execute_input": "2023-04-17T07:25:11.986244Z",
          "iopub.status.idle": "2023-04-17T07:25:11.994720Z",
          "shell.execute_reply.started": "2023-04-17T07:25:11.986204Z",
          "shell.execute_reply": "2023-04-17T07:25:11.993505Z"
        },
        "trusted": true,
        "id": "1hzRSFmnQ-QD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop(model, trainloader, loss_fn, epochs, optimizer):  \n",
        "    steps = 0\n",
        "    steps_per_epoch = len(trainloader) \n",
        "    min_loss = 1000000\n",
        "    max_accuracy = 0\n",
        "    trigger = 0\n",
        "    patience = 7 \n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train() # 훈련 모드\n",
        "        train_loss = 0\n",
        "        for batch in trainloader: # 이터레이터로부터 next()가 호출되며 미니배치를 반환(images, labels)\n",
        "            steps += 1\n",
        "            # images, labels : (torch.Size([16, 3, 224, 224]), torch.Size([16]))\n",
        "            # 0. Data를 GPU로 보내기\n",
        "            images = batch['image']\n",
        "            labels = batch['label']\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            # 1. 입력 데이터 준비\n",
        "            # not Flatten !!\n",
        "            # images.resize_(images.shape[0], 784) \n",
        "\n",
        "            # 2. 전방향(forward) 예측\n",
        "            predict = model(images) # 예측 점수\n",
        "            loss = loss_fn(predict, labels) # 예측 점수와 정답을 CrossEntropyLoss에 넣어 Loss값 반환\n",
        "\n",
        "            # 3. 역방향(backward) 오차(Gradient) 전파\n",
        "            optimizer.zero_grad() # Gradient가 누적되지 않게 하기 위해\n",
        "            loss.backward() # 모델파리미터들의 Gradient 전파\n",
        "\n",
        "            # 4. 경사 하강법으로 모델 파라미터 업데이트\n",
        "            optimizer.step() # W <- W -lr*Gradient\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            if (steps % steps_per_epoch) == 0 : \n",
        "                model.eval() # 평가 모드 : 평가에서 사용하지 않을 계층(배치 정규화, 드롭아웃)들을 수행하지 않게 하기 위해서\n",
        "                valid_loss, valid_accuracy = validate(model, validloader, loss_fn)\n",
        "            # -------------------------------------------\n",
        "\n",
        "                print('Epoch : {}/{}.......'.format(epoch+1, epochs),            \n",
        "                   'Train Loss : {:.3f}'.format(train_loss/len(trainloader)), \n",
        "                   'Valid Loss : {:.3f}'.format(valid_loss/len(validloader)), \n",
        "                   'Valid Accuracy : {:.3f}'.format(valid_accuracy)            \n",
        "                      )\n",
        "\n",
        "              # Best model 저장    \n",
        "              # option 1 : valid_loss 모니터링\n",
        "              # if valid_loss < min_loss: # 바로 이전 epoch의 loss보다 작으면 저장하기\n",
        "              #   min_loss = valid_loss\n",
        "              #   best_model_state = deepcopy(model.state_dict())          \n",
        "              #   torch.save(best_model_state, 'best_checkpoint.pth')     \n",
        "\n",
        "              # option 2 : valid_accuracy 모니터링      \n",
        "                if valid_accuracy > max_accuracy : # 바로 이전 epoch의 accuracy보다 크면 저장하기\n",
        "                    max_accuracy = valid_accuracy\n",
        "                    best_model_state = deepcopy(model.state_dict())          \n",
        "                    torch.save(best_model_state, 'best_checkpoint.pth')  \n",
        "              # -------------------------------------------\n",
        "\n",
        "              # Early Stopping (조기 종료)\n",
        "                if valid_loss > min_loss: # valid_loss가 min_loss를 갱신하지 못하면\n",
        "                    trigger += 1\n",
        "                    print('trigger : ', trigger)\n",
        "                if trigger > patience:\n",
        "                    print('Early Stopping !!!')\n",
        "                    print('Training loop is finished !!')\n",
        "                    return\n",
        "                else:\n",
        "                    trigger = 0\n",
        "                    min_loss = valid_loss\n",
        "                # -------------------------------------------\n",
        "\n",
        "                # Learning Rate Scheduler\n",
        "                scheduler.step(valid_loss)\n",
        "            # -------------------------------------------\n",
        "\n",
        "    return  "
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-17T07:25:14.024623Z",
          "iopub.execute_input": "2023-04-17T07:25:14.025035Z",
          "iopub.status.idle": "2023-04-17T07:25:14.037925Z",
          "shell.execute_reply.started": "2023-04-17T07:25:14.024999Z",
          "shell.execute_reply": "2023-04-17T07:25:14.036863Z"
        },
        "trusted": true,
        "id": "HBux4YKnQ-QD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 55\n",
        "%time train_loop(model, trainloader, loss_fn, epochs, optimizer)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-17T07:25:16.258668Z",
          "iopub.execute_input": "2023-04-17T07:25:16.259043Z",
          "iopub.status.idle": "2023-04-17T09:13:32.839952Z",
          "shell.execute_reply.started": "2023-04-17T07:25:16.259010Z",
          "shell.execute_reply": "2023-04-17T09:13:32.838859Z"
        },
        "trusted": true,
        "id": "UXJK0w_kQ-QE",
        "outputId": "35f2b943-f812-433b-fe35-ef2c784037e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 1/55....... Train Loss : 1.951 Valid Loss : 1.073 Valid Accuracy : 0.702\n",
            "Epoch : 2/55....... Train Loss : 1.189 Valid Loss : 1.034 Valid Accuracy : 0.718\n",
            "Epoch : 3/55....... Train Loss : 1.075 Valid Loss : 0.997 Valid Accuracy : 0.727\n",
            "Epoch : 4/55....... Train Loss : 1.052 Valid Loss : 1.125 Valid Accuracy : 0.705\n",
            "trigger :  1\n",
            "Epoch : 5/55....... Train Loss : 0.986 Valid Loss : 1.094 Valid Accuracy : 0.727\n",
            "Epoch : 6/55....... Train Loss : 0.969 Valid Loss : 1.119 Valid Accuracy : 0.718\n",
            "trigger :  1\n",
            "Epoch : 7/55....... Train Loss : 0.959 Valid Loss : 1.091 Valid Accuracy : 0.736\n",
            "Epoch : 8/55....... Train Loss : 0.910 Valid Loss : 1.133 Valid Accuracy : 0.735\n",
            "trigger :  1\n",
            "Epoch 00008: reducing learning rate of group 0 to 1.0000e-04.\n",
            "Epoch : 9/55....... Train Loss : 0.614 Valid Loss : 0.854 Valid Accuracy : 0.779\n",
            "Epoch : 10/55....... Train Loss : 0.583 Valid Loss : 0.853 Valid Accuracy : 0.780\n",
            "Epoch : 11/55....... Train Loss : 0.571 Valid Loss : 0.825 Valid Accuracy : 0.773\n",
            "Epoch : 12/55....... Train Loss : 0.561 Valid Loss : 0.860 Valid Accuracy : 0.775\n",
            "trigger :  1\n",
            "Epoch : 13/55....... Train Loss : 0.557 Valid Loss : 0.847 Valid Accuracy : 0.772\n",
            "Epoch : 14/55....... Train Loss : 0.554 Valid Loss : 0.827 Valid Accuracy : 0.776\n",
            "Epoch : 15/55....... Train Loss : 0.542 Valid Loss : 0.855 Valid Accuracy : 0.771\n",
            "trigger :  1\n",
            "Epoch : 16/55....... Train Loss : 0.550 Valid Loss : 0.771 Valid Accuracy : 0.784\n",
            "Epoch : 17/55....... Train Loss : 0.538 Valid Loss : 0.827 Valid Accuracy : 0.773\n",
            "trigger :  1\n",
            "Epoch : 18/55....... Train Loss : 0.530 Valid Loss : 0.839 Valid Accuracy : 0.771\n",
            "trigger :  1\n",
            "Epoch : 19/55....... Train Loss : 0.542 Valid Loss : 0.840 Valid Accuracy : 0.776\n",
            "trigger :  1\n",
            "Epoch : 20/55....... Train Loss : 0.517 Valid Loss : 0.810 Valid Accuracy : 0.771\n",
            "Epoch : 21/55....... Train Loss : 0.530 Valid Loss : 0.822 Valid Accuracy : 0.783\n",
            "trigger :  1\n",
            "Epoch 00021: reducing learning rate of group 0 to 1.0000e-05.\n",
            "Epoch : 22/55....... Train Loss : 0.508 Valid Loss : 0.812 Valid Accuracy : 0.774\n",
            "Epoch : 23/55....... Train Loss : 0.509 Valid Loss : 0.776 Valid Accuracy : 0.777\n",
            "Epoch : 24/55....... Train Loss : 0.485 Valid Loss : 0.819 Valid Accuracy : 0.777\n",
            "trigger :  1\n",
            "Epoch : 25/55....... Train Loss : 0.493 Valid Loss : 0.794 Valid Accuracy : 0.774\n",
            "Epoch : 26/55....... Train Loss : 0.493 Valid Loss : 0.828 Valid Accuracy : 0.781\n",
            "trigger :  1\n",
            "Epoch 00026: reducing learning rate of group 0 to 1.0000e-06.\n",
            "Epoch : 27/55....... Train Loss : 0.490 Valid Loss : 0.792 Valid Accuracy : 0.786\n",
            "Epoch : 28/55....... Train Loss : 0.486 Valid Loss : 0.781 Valid Accuracy : 0.788\n",
            "Epoch : 29/55....... Train Loss : 0.492 Valid Loss : 0.810 Valid Accuracy : 0.780\n",
            "trigger :  1\n",
            "Epoch : 30/55....... Train Loss : 0.499 Valid Loss : 0.838 Valid Accuracy : 0.773\n",
            "trigger :  1\n",
            "Epoch : 31/55....... Train Loss : 0.479 Valid Loss : 0.828 Valid Accuracy : 0.771\n",
            "Epoch 00031: reducing learning rate of group 0 to 1.0000e-07.\n",
            "Epoch : 32/55....... Train Loss : 0.476 Valid Loss : 0.798 Valid Accuracy : 0.781\n",
            "Epoch : 33/55....... Train Loss : 0.490 Valid Loss : 0.797 Valid Accuracy : 0.774\n",
            "Epoch : 34/55....... Train Loss : 0.485 Valid Loss : 0.809 Valid Accuracy : 0.785\n",
            "trigger :  1\n",
            "Epoch : 35/55....... Train Loss : 0.489 Valid Loss : 0.808 Valid Accuracy : 0.778\n",
            "Epoch : 36/55....... Train Loss : 0.497 Valid Loss : 0.826 Valid Accuracy : 0.771\n",
            "trigger :  1\n",
            "Epoch 00036: reducing learning rate of group 0 to 1.0000e-08.\n",
            "Epoch : 37/55....... Train Loss : 0.481 Valid Loss : 0.805 Valid Accuracy : 0.779\n",
            "Epoch : 38/55....... Train Loss : 0.502 Valid Loss : 0.811 Valid Accuracy : 0.780\n",
            "trigger :  1\n",
            "Epoch : 39/55....... Train Loss : 0.495 Valid Loss : 0.803 Valid Accuracy : 0.784\n",
            "Epoch : 40/55....... Train Loss : 0.484 Valid Loss : 0.820 Valid Accuracy : 0.772\n",
            "trigger :  1\n",
            "Epoch : 41/55....... Train Loss : 0.473 Valid Loss : 0.804 Valid Accuracy : 0.786\n",
            "Epoch : 42/55....... Train Loss : 0.484 Valid Loss : 0.838 Valid Accuracy : 0.769\n",
            "trigger :  1\n",
            "Epoch : 43/55....... Train Loss : 0.483 Valid Loss : 0.773 Valid Accuracy : 0.783\n",
            "Epoch : 44/55....... Train Loss : 0.481 Valid Loss : 0.806 Valid Accuracy : 0.773\n",
            "trigger :  1\n",
            "Epoch : 45/55....... Train Loss : 0.483 Valid Loss : 0.836 Valid Accuracy : 0.776\n",
            "trigger :  1\n",
            "Epoch : 46/55....... Train Loss : 0.496 Valid Loss : 0.821 Valid Accuracy : 0.781\n",
            "Epoch : 47/55....... Train Loss : 0.481 Valid Loss : 0.766 Valid Accuracy : 0.792\n",
            "Epoch : 48/55....... Train Loss : 0.479 Valid Loss : 0.790 Valid Accuracy : 0.783\n",
            "trigger :  1\n",
            "Epoch : 49/55....... Train Loss : 0.474 Valid Loss : 0.796 Valid Accuracy : 0.786\n",
            "trigger :  1\n",
            "Epoch : 50/55....... Train Loss : 0.486 Valid Loss : 0.777 Valid Accuracy : 0.784\n",
            "Epoch : 51/55....... Train Loss : 0.482 Valid Loss : 0.811 Valid Accuracy : 0.776\n",
            "trigger :  1\n",
            "Epoch : 52/55....... Train Loss : 0.490 Valid Loss : 0.841 Valid Accuracy : 0.771\n",
            "trigger :  1\n",
            "Epoch : 53/55....... Train Loss : 0.470 Valid Loss : 0.793 Valid Accuracy : 0.776\n",
            "Epoch : 54/55....... Train Loss : 0.493 Valid Loss : 0.818 Valid Accuracy : 0.779\n",
            "trigger :  1\n",
            "Epoch : 55/55....... Train Loss : 0.483 Valid Loss : 0.818 Valid Accuracy : 0.773\n",
            "CPU times: user 1h 51min 15s, sys: 7min 18s, total: 1h 58min 34s\n",
            "Wall time: 1h 51min 6s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_iter = iter(testloader)\n",
        "batch = next(test_iter)\n",
        "images = batch['image']\n",
        "labels = batch['label']\n",
        "\n",
        "images, labels = images.to(device), labels.to(device)\n",
        "print(images.size(), labels.size())"
      ],
      "metadata": {
        "id": "6DaA91aRQ-QE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bc7f5bd-45d2-4b6d-9f9c-acbb3ed8e70e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 3, 224, 224]) torch.Size([16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluation(model, testloader, loss_fn):\n",
        "    total = 0   \n",
        "    correct = 0\n",
        "    test_loss = 0\n",
        "    test_accuracy = 0\n",
        "\n",
        "  # 전방향 예측을 구할 때는 gradient가 필요가 없음음\n",
        "    with torch.no_grad():\n",
        "        for images, labels in testloader: # 이터레이터로부터 next()가 호출되며 미니배치를 반환(images, labels)\n",
        "          # 0. Data를 GPU로 보내기\n",
        "            images = batch['image']\n",
        "            labels = batch['label']\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "          # 1. 입력 데이터 준비\n",
        "          # not Flatten\n",
        "          # images.resize_(images.size()[0], 784)\n",
        "      \n",
        "          # 2. 전방향(Forward) 예측\n",
        "            logit = model(images) # 예측 점수\n",
        "            _, preds = torch.max(logit, 1) # 배치에 대한 최종 예측\n",
        "            # preds = logit.max(dim=1)[1] \n",
        "            correct += int((preds == labels).sum()) # 배치치 중 맞은 것의 개수가 correct에 누적\n",
        "            total += labels.shape[0] # 배치 사이즈만큼씩 total에 누적\n",
        "\n",
        "            loss = loss_fn(logit, labels)\n",
        "            test_loss += loss.item() # tensor에서 값을 꺼내와서, 배치의 loss 평균값을 valid_loss에 누적\n",
        "        \n",
        "        test_accuracy = correct / total\n",
        "   \n",
        "        print('Test Loss : {:.3f}'.format(test_loss/len(testloader)), \n",
        "        'Test Accuracy : {:.3f}'.format(test_accuracy))\n",
        "\n",
        "model.eval()\n",
        "evaluation(model, testloader, loss_fn)  "
      ],
      "metadata": {
        "id": "l4xpv-C8NfBD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55893837-eace-4e93-f93f-8490a3d9094c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss : 0.402 Test Accuracy : 0.875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'last_checkpoint_6.pth')"
      ],
      "metadata": {
        "id": "NfFVBDjc4YeK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 시간이 흐른뒤 다시 모델 가져오기\n",
        "last_state_dict_6 = torch.load('last_checkpoint_6.pth')"
      ],
      "metadata": {
        "id": "MGdRM-DR4YbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 읽어들인 모델 파라미터는 모델 아키텍처에 연결을 시켜줘야 함\n",
        "# load_state_dict() 사용\n",
        "last_model_6 = model\n",
        "last_model_6.to(device)\n",
        "last_model_6.load_state_dict(last_state_dict_6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNxA42mf4YYh",
        "outputId": "618cf519-1e77-4756-b4e0-27c91c854e5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "last_model_6.eval()\n",
        "evaluation(last_model_6, testloader, loss_fn) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AXQ5yqZ4xrx",
        "outputId": "f9af562a-2f3a-4a95-f208-7f015b0d91ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss : 0.402 Test Accuracy : 0.875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# valid loss or accuracy 기준 best model\n",
        "best_state_dict_6 = torch.load('best_checkpoint.pth')\n",
        "best_model_6 = model\n",
        "best_model_6.to(device)\n",
        "best_model_6.load_state_dict(best_state_dict_6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4O3banvh4xpR",
        "outputId": "191e30ef-090e-4c2e-f267-d8b1724ca74e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_6.eval()\n",
        "evaluation(best_model_6, testloader, loss_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMjhO7Gd4xnJ",
        "outputId": "73431920-7abe-408e-982c-01f39b05cf6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss : 0.457 Test Accuracy : 0.938\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "90vF_USI4xk5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hij81KSw4xih"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}